{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive-Bayes.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPePPOUwdG0chzHGSYdKsSr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonNData/naive_bayes/blob/master/notebooks/Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6Lb44tkJVbs",
        "colab_type": "text"
      },
      "source": [
        "## Naive Bayes\n",
        "Multinomial \n",
        "Need a class.  \n",
        "Fit and predict methods.  \n",
        "\n",
        "\n",
        "*   Fit will get the histogram frequency, and train the model, update attributes.\n",
        "-- Need a feature vector, row is obs, columns are features, numerical\n",
        "*   Predict will classify the observation  \n",
        "\n",
        "  \n",
        "\n",
        "What's the input? Needs to be categorical but that can be easily arranged.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4UMwJs63Pq1",
        "colab_type": "text"
      },
      "source": [
        "## Quick Example with Balance Scale data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU2oSj5ZJUjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyGcA8zgOQKo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "headers = ['class_name', 'left-weight', 'left-distance', 'right-weight', 'right-distance']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBaDn8EPN-qy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "449a4cbd-744f-4a7e-ab83-a75f0ae51a7b"
      },
      "source": [
        "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/balance-scale/balance-scale.data', names=headers)\n",
        "df"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "URLError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1324\u001b[0m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0;32m-> 1325\u001b[0;31m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[0m\u001b[1;32m   1326\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1263\u001b[0m         \u001b[0;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1264\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1309\u001b[0m             \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1310\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mendheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1258\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36m_send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1038\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1039\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    975\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 976\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    977\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1417\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/http/client.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    947\u001b[0m         self.sock = self._create_connection(\n\u001b[0;32m--> 948\u001b[0;31m             (self.host,self.port), self.timeout, self.source_address)\n\u001b[0m\u001b[1;32m    949\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIPPROTO_TCP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTCP_NODELAY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address)\u001b[0m\n\u001b[1;32m    712\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m             \u001b[0;31m# Break explicitly a reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d63feeb1b5d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://archive.ics.uci.edu/ml/machine-learning-databases/balance-scale/balance-scale.data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;31m# See https://github.com/python/mypy/issues/1297\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     fp_or_buf, _, compression, should_close = get_filepath_or_buffer(\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     )\n\u001b[1;32m    433\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression, mode)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content-Encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gzip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;31m# post-process response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    542\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0;32m--> 544\u001b[0;31m                                   '_open', req)\n\u001b[0m\u001b[1;32m    545\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0;32m-> 1368\u001b[0;31m                 context=self._context, check_hostname=self._check_hostname)\n\u001b[0m\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m         \u001b[0mhttps_request\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractHTTPHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_request_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mdo_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n\u001b[1;32m   1326\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# timeout error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 110] Connection timed out>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-OJBZwDOruo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = train_test_split(df, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tplK6SW3PVQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = train.drop(columns='class_name')\n",
        "X_test = test.drop(columns='class_name')\n",
        "\n",
        "y_train = train['class_name'].apply(lambda x: 0 if x==\"L\" else 1) \n",
        "y_test = test['class_name'].apply(lambda x: 0 if x==\"L\" else 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx4THrnahy6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjDHLVOy2yfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnb = MultinomialNB()\n",
        "mnb.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yi_Fg-qn297X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = mnb.predict(X_test)\n",
        "accuracy_score(y_test, y_pred=y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItRielG55D-8",
        "colab_type": "text"
      },
      "source": [
        "## Now to make the class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYBWra0n5Ce7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksB4dySl69L5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GaussBayes:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "  def fit(self, X_train, y_train):\n",
        "    # Get information about the array\n",
        "    num_obs, num_features = X_train.shape\n",
        "    \n",
        "    # Get array of unique targets\n",
        "    self.u_classes = np.unique(y_train)\n",
        "    num_classes = len(self.u_classes)\n",
        "\n",
        "    # intialize mean, variance, priors with correct size\n",
        "    self.X_train_mean = np.zeros((num_classes, num_features), dtype=np.float64)\n",
        "    self.var = np.zeros((num_classes, num_features), dtype=np.float64)\n",
        "    self.priors = np.zeros(num_classes, dtype=np.float64)\n",
        "\n",
        "    # Calculate\n",
        "    for i,cls in enumerate(self.u_classes):\n",
        "      # specify only values where the class is the same as the target\n",
        "      X_train_cls = X_train[cls==y_train]\n",
        "      # the mean from this class and all columns\n",
        "      self.X_train_mean[cls,:] = X_train_cls.mean(axis=0)\n",
        "      self.var[cls,:] = X_train_cls.var(axis=0)\n",
        "      self.priors[cls] = X_train_cls.shape[0] / float(num_obs) # how often this class is occuring\n",
        "\n",
        "  def predict(self, X_test):\n",
        "    y_pred = [self._predict(x) for x in X_test]\n",
        "    return y_pred\n",
        "\n",
        "  def _predict(self, X_test):\n",
        "    posteriors =  []\n",
        "\n",
        "    for i, cls in enumerate(self.u_classes):\n",
        "      prior = np.log(self.priors[i])\n",
        "      class_conditional = np.sum(np.log(self._prob_density(i, X_test)))\n",
        "      posterior =  prior + class_conditional\n",
        "      posteriors.append(posterior)\n",
        "    \n",
        "    return self.u_classes[np.argmax(posteriors)] # argmax gives index of max value\n",
        "\n",
        "  def _prob_density(self, class_idx, x):\n",
        "      mean = self.X_train_mean[class_idx]\n",
        "      var = self.var[class_idx]\n",
        "      numerator = np.exp(- (x-mean)**2 / (2 * var))\n",
        "      denominator = np.sqrt(2 * np.pi * var)\n",
        "      return numerator / denominator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uztS9RaABxNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gb = GaussBayes()\n",
        "gb.fit(X_train, y_train)\n",
        "y_pred = gb.predict(X_test)\n",
        "accuracy_score(y_test, y_pred=y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfNNXTD4Cavj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NaiveBayes:\n",
        "    def __init__(self, X, y):\n",
        "        self.num_examples, self.num_features = X.shape\n",
        "        self.num_classes = len(np.unique(y))\n",
        "        self.eps = 1e-6\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes_mean = {}\n",
        "        self.classes_variance = {}\n",
        "        self.classes_prior = {}\n",
        "\n",
        "        for c in range(self.num_classes):\n",
        "            X_c = X[y == c]\n",
        "\n",
        "            self.classes_mean[str(c)] = np.mean(X_c, axis=0)\n",
        "            self.classes_variance[str(c)] = np.var(X_c, axis=0)\n",
        "            self.classes_prior[str(c)] = X_c.shape[0] / X.shape[0]\n",
        "\n",
        "    def predict(self, X):\n",
        "        probs = np.zeros((self.num_examples, self.num_classes))\n",
        "\n",
        "        for c in range(self.num_classes):\n",
        "            prior = self.classes_prior[str(c)]\n",
        "            probs_c = self.density_function(\n",
        "                X, self.classes_mean[str(c)], self.classes_variance[str(c)]\n",
        "            )\n",
        "            probs[:, c] = probs_c + np.log(prior)\n",
        "\n",
        "        return np.argmax(probs, 1)\n",
        "\n",
        "    def density_function(self, x, mean, sigma):\n",
        "        # Calculate probability from Gaussian density function\n",
        "        const = -self.num_features / 2 * np.log(2 * np.pi) - 0.5 * np.sum(\n",
        "            np.log(sigma + self.eps)\n",
        "        )\n",
        "        probs = 0.5 * np.sum(np.power(x - mean, 2) / (sigma + self.eps), 1)\n",
        "        return const - probs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-PJWFFcUI3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.drop(X_test.tail(-1).index, inplace=True)\n",
        "y_test.drop(X_test.tail(-1).index, inplace=True)\n",
        "nb = NaiveBayes(X_train, y_train)\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred = nb.predict(X_test)\n",
        "accuracy_score(y_test, y_pred=y_pred)\n",
        "# Problem here is that test must be the same shape...."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0e6xpuCEUZGp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NaiveBayes:\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self._classes = np.unique(y)\n",
        "        n_classes = len(self._classes)\n",
        "\n",
        "        # calculate mean, var, and prior for each class\n",
        "        self._mean = np.zeros((n_classes, n_features), dtype=np.float64)\n",
        "        self._var = np.zeros((n_classes, n_features), dtype=np.float64)\n",
        "        self._priors =  np.zeros(n_classes, dtype=np.float64)\n",
        "\n",
        "        for idx, c in enumerate(self._classes):\n",
        "            X_c = X[y==c]\n",
        "            self._mean[idx, :] = X_c.mean(axis=0)\n",
        "            self._var[idx, :] = X_c.var(axis=0)\n",
        "            self._priors[idx] = X_c.shape[0] / float(n_samples)\n",
        "\n",
        "    def predict(self, X):\n",
        "        y_pred = [self._predict(x) for x in X]\n",
        "        return np.array(y_pred)\n",
        "\n",
        "    def _predict(self, x):\n",
        "        posteriors = []\n",
        "\n",
        "        # calculate posterior probability for each class\n",
        "        for idx, c in enumerate(self._classes):\n",
        "            prior = np.log(self._priors[idx])\n",
        "            posterior = np.sum(np.log(self._pdf(idx, x)))\n",
        "            posterior = prior + posterior\n",
        "            posteriors.append(posterior)\n",
        "            \n",
        "        # return class with highest posterior probability\n",
        "        return self._classes[np.argmax(posteriors)]\n",
        "            \n",
        "\n",
        "    def _pdf(self, class_idx, x):\n",
        "        mean = self._mean[class_idx]\n",
        "        var = self._var[class_idx]\n",
        "        numerator = np.exp(- (x-mean)**2 / (2 * var))\n",
        "        denominator = np.sqrt(2 * np.pi * var)\n",
        "        return numerator / denominator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egAQSW37iMJG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb = NaiveBayes()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred = nb.predict(X_test)\n",
        "accuracy_score(y_test, y_pred=y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwRLI8RRA3yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultiNayes:\n",
        "    \"\"\"\n",
        "    Multinomial Naive Bayes algorithm.\n",
        "    Paramaters\n",
        "    ----------\n",
        "    alpha : float, default=1.0\n",
        "        Smoothing paramater, can be set to smaller values\n",
        "        (0 for no smoothing)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, alpha=1.0):\n",
        "        self.alpha = alpha\n",
        "        self.fitted = False\n",
        "\n",
        "    def label_binarizer(self, y, classes=None, bin_labels=None):\n",
        "        \"\"\"convert labels into an array of shape\n",
        "           (length of y, number of classes). This\n",
        "           will assist in getting the log priors and probabilities\"\"\"\n",
        "        if classes is None:\n",
        "            classes = np.unique(y)\n",
        "            bin_labels = np.zeros((y.shape[0], classes.shape[0]))\n",
        "            self.classes = classes\n",
        "            self.bin_labels = bin_labels\n",
        "\n",
        "        if bin_labels.shape[0] < 1:\n",
        "            return None\n",
        "\n",
        "        x = np.where(classes == y[0])\n",
        "        bin_labels[0][x] = 1\n",
        "\n",
        "        return self.label_binarizer(y[1:], classes, bin_labels[1:])\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        # if X is not np.ndarray, convert from csr with `toarray()`\n",
        "        if type(X) is not np.ndarray:\n",
        "            X = X.to_numpy()\n",
        "\n",
        "        self.label_binarizer(y)\n",
        "\n",
        "        n_classes = self.classes.shape[0]\n",
        "        n_features = X.shape[1]\n",
        "\n",
        "        # initialize counter arrays\n",
        "        self.class_count = np.zeros(n_classes)\n",
        "        self.feature_count = np.zeros((n_classes, n_features))\n",
        "\n",
        "        # count classes and features by getting\n",
        "        # dot product of transposed binary labels\n",
        "        # they are automatically separated into their\n",
        "        # appropriate arrays\n",
        "        self.feature_count += np.dot(self.bin_labels.T, X)\n",
        "        self.class_count += self.bin_labels.sum(axis=0)\n",
        "\n",
        "        # add smoothing\n",
        "        if self.alpha > 0.0:\n",
        "            self.feature_count += self.alpha\n",
        "            smoothed_class_count = self.feature_count.sum(axis=1)\n",
        "\n",
        "            # get conditional log probabilities\n",
        "            self.feat_log_probs = (np.log(self.feature_count) -\n",
        "                                   np.log(smoothed_class_count.reshape(-1, 1)))\n",
        "        else:\n",
        "            print(\n",
        "                f\"Alpha is {self.alpha}. A value this small will cause \"\n",
        "                \"result in errors when feature count is 0\"\n",
        "            )\n",
        "            self.feat_log_probs = np.log(\n",
        "                                    self.feature_count /\n",
        "                                    self.feature_count\n",
        "                                    .sum(axis=1)\n",
        "                                    .reshape(-1, 1)\n",
        "                                  )\n",
        "\n",
        "        # get log priors\n",
        "        self.class_log_priors = (np.log(self.class_count) -\n",
        "                                 np.log(self.class_count\n",
        "                                 .sum(axis=0)\n",
        "                                 .reshape(-1, 1)))\n",
        "\n",
        "        self.fitted = True\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict target from features of X\"\"\"\n",
        "\n",
        "        # check if model has fit data\n",
        "        if not self.fitted:\n",
        "            print(\"The classifier has not yet \"\n",
        "                  \"been fit. Not executing predict\")\n",
        "\n",
        "        if type(X) is not np.ndarray:\n",
        "            X = X.toarray()\n",
        "\n",
        "        scores = np.dot(X, self.feat_log_probs.T) + self.class_log_priors\n",
        "\n",
        "        predictions = self.classes[np.argmax(scores, axis=1)]\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def accuracy(self, y_pred, y):\n",
        "        points = (y_pred == y).astype(int)\n",
        "        score = points.sum() / points.shape[0]\n",
        "\n",
        "        return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHglF0lqA55F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf = MultiNayes()\n",
        "\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred=y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSOvJyPj_USb",
        "colab_type": "text"
      },
      "source": [
        "## Bernoulli"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOGeNoHMc9zI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "  text = text.lower() # convert to lowercase\n",
        "  stop_chars = '''0123456789!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "\n",
        "\n",
        "  # To take input from the user\n",
        "  # my_str = input(\"Enter a string: \")\n",
        "\n",
        "  # remove punctuation from the string\n",
        "  tokens = \"\"\n",
        "  for char in text:\n",
        "    if char not in stop_chars:\n",
        "        tokens += char\n",
        "\n",
        "  return tokens.split()\n",
        "\n",
        "def count_words(training_set):\n",
        "  \"\"\" \n",
        "  input is (message, category) where the category is 0 or 1\n",
        "  output is counts = {word1: [num_cat1, num_cat2], word2: [num_cat1, num_cat2]...}\n",
        "  \"\"\"\n",
        "  counts = {}\n",
        "  for message, category in training_set:\n",
        "    for word in tokenize(message):\n",
        "      if word not in counts:\n",
        "        counts[word] = [0,0]\n",
        "      counts[word][category] += 1\n",
        "  return counts\n",
        "\n",
        "def word_probabilities(counts, total_cat_1, total_cat_2, k=0.5):\n",
        "  \"\"\"turn the word_counts into a list of triplets\n",
        "  w, p(w | cat1) and p(w | cat2)\"\"\"\n",
        "  word, \n",
        "  return [(w,\n",
        "  (spam + k) / (total_spams + 2 * k),\n",
        "  (non_spam + k) / (total_non_spams + 2 * k))\n",
        "  for w, (spam, non_spam) in counts.items()]\n",
        "\n",
        "def spam_probability(word_probs, message):\n",
        "  message_words = tokenize(message)\n",
        "  log_prob_if_spam = log_prob_if_not_spam = 0.0\n",
        "  # iterate through each word in our vocabulary\n",
        "  for word, prob_if_spam, prob_if_not_spam in word_probs:\n",
        "    # if *word* appears in the message,\n",
        "    # add the log probability of seeing it\n",
        "    if word in message_words:\n",
        "      log_prob_if_spam += math.log(prob_if_spam)\n",
        "      log_prob_if_not_spam += math.log(prob_if_not_spam)\n",
        "    # if *word* doesn't appear in the message\n",
        "  # add the log probability of _not_ seeing it\n",
        "  # which is log(1 - probability of seeing it)\n",
        "    else:\n",
        "      log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
        "      log_prob_if_not_spam += math.log(1.0 - prob_if_not_spam)\n",
        "\n",
        "  prob_if_spam = math.exp(log_prob_if_spam)\n",
        "  prob_if_not_spam = math.exp(log_prob_if_not_spam)\n",
        "  return prob_if_spam / (prob_if_spam + prob_if_not_spam)\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdjsGvW42nte",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NaiveBayesClassifier:\n",
        "  def __init__(self, k=0.5):\n",
        "    self.k = k\n",
        "    self.word_probs = []\n",
        "  def train(self, training_set):\n",
        "    # count spam and non-spam messages\n",
        "    num_spams = len([is_spam\n",
        "    for message, is_spam in training_set\n",
        "    if is_spam])\n",
        "    num_non_spams = len(training_set) - num_spams\n",
        "    # run training data through our \"pipeline\"\n",
        "    word_counts = count_words(training_set)\n",
        "    self.word_probs = word_probabilities(word_counts,\n",
        "    num_spams,\n",
        "    num_non_spams,\n",
        "    self.k)\n",
        "  def classify(self, message):\n",
        "    return spam_probability(self.word_probs, message)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZkPMdBP3F8W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nbc = NaiveBayesClassifier()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbDjlTKCFwJJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Let's say input is [(\"sample text1\", label1), (\"sample text2\", label2)]\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI_GCxkbNe_Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "5af4921b-3312-40fe-8cb6-6d5e6ba59801"
      },
      "source": [
        "text = \"will this work? The rights among men can be strenuous...\"\n",
        "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "\n",
        "\n",
        "# To take input from the user\n",
        "# my_str = input(\"Enter a string: \")\n",
        "\n",
        "# remove punctuation from the string\n",
        "no_punct = \"\"\n",
        "for char in text:\n",
        "   if char not in punctuations:\n",
        "       no_punct = no_punct + char\n",
        "no_punct.split()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['will',\n",
              " 'this',\n",
              " 'work',\n",
              " 'The',\n",
              " 'rights',\n",
              " 'among',\n",
              " 'men',\n",
              " 'can',\n",
              " 'be',\n",
              " 'strenuous']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9Rt3ImXu7yz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize1(text):\n",
        "  text = text.lower() # convert to lowercase\n",
        "  stop_chars = '''0123456789!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "\n",
        "\n",
        "  # To take input from the user\n",
        "  # my_str = input(\"Enter a string: \")\n",
        "\n",
        "  # remove punctuation from the string\n",
        "  tokens = \"\"\n",
        "  for char in text:\n",
        "    if char not in stop_chars:\n",
        "        tokens += char\n",
        "\n",
        "  return set(tokens.split())"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLgMtsG6xAw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_words(training_set):\n",
        "  \"\"\" \n",
        "  input is (message, category) where the category is 0 or 1\n",
        "  output is counts = {word1: [num_cat1, num_cat2], word2: [num_cat1, num_cat2]...}\n",
        "  \"\"\"\n",
        "  counts = {}\n",
        "  for message, category in training_set:\n",
        "    for word in tokenize1(message):\n",
        "      if word not in counts:\n",
        "        counts[word] = [0,0]\n",
        "      counts[word][category] += 1\n",
        "  return counts\n",
        "\n",
        "def word_probabilities(counts, total_cat_1, total_cat_2, k=0.5):\n",
        "  \"\"\"turn the word_counts into a list of triplets\n",
        "  w, p(w | cat1) and p(w | cat2)\"\"\"\n",
        "  return [(w,\n",
        "  (cat1 + k) / (total_cat_1 + 2 * k),\n",
        "  (total_cat_2 + k) / (total_cat_2 + 2 * k))\n",
        "  for w, (cat1, cat2) in counts.items()]\n",
        "\n",
        "def cat_probability(word_probs, message):\n",
        "  message_words = tokenize1(message)\n",
        "  log_prob_cat_1 = log_prob_cat_2 = 0.0\n",
        "  # iterate through each word in our vocabulary\n",
        "  for word, prob_cat_1, prob_cat_2 in word_probs:\n",
        "    # if *word* appears in the message,\n",
        "    # add the log probability of seeing it\n",
        "    if word in message_words:\n",
        "      log_prob_cat_1 += np.log(prob_cat_1)\n",
        "      log_prob_cat_2 += np.log(prob_cat_2)\n",
        "    # if *word* doesn't appear in the message\n",
        "  # add the log probability of _not_ seeing it\n",
        "  # which is log(1 - probability of seeing it)\n",
        "    else:\n",
        "      log_prob_if_spam += np.log(1.0 - prob_if_spam)\n",
        "      log_prob_if_not_spam += np.log(1.0 - prob_if_not_spam)\n",
        "\n",
        "  prob_if_spam = np.exp(log_prob_if_spam)\n",
        "  prob_if_not_spam = np.exp(log_prob_if_not_spam)\n",
        "  return prob_if_spam / (prob_if_spam + prob_if_not_spam)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hATo4-Mv-E-9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc330ce2-76e2-4293-b844-8f99fce51b93"
      },
      "source": [
        "trainin = [\n",
        "           (\"\"\"Our second function will count the words in a labeled training set of messages. Weâ€™ll have\n",
        "it return a dictionary whose keys are words, and whose values are two-element lists\n",
        "[spam_count, non_spam_count] corresponding to how many times we saw that word in\n",
        "both spam and nonspam messages:\n",
        "\"\"\", 0),\n",
        "(\"\"\"Our next step is to turn these counts into estimated probabilities using the smoothing we\n",
        "described before. Our function will return a list of triplets containing each word, the\n",
        "probability of seeing that word in a spam message, and the probability of seeing that word\n",
        "in a nonspam message:\"\"\", 1),\n",
        "(\"\"\"The last piece is to use these word probabilities (and our Naive Bayes assumptions) to\n",
        "assign probabilities to messages\"\"\", 0)\n",
        "]\n",
        "# count spam and non-spam messages\n",
        "num_cat_1 = len([cat\n",
        "for message, cat in trainin\n",
        "if cat==0])\n",
        "num_cat_2 = len(trainin) - num_cat_1\n",
        "word_counts = count_words(trainin)\n",
        "\n",
        "word_probs = word_probabilities(word_counts, num_cat_1, num_cat_2)\n",
        "message = \"The last piece is to use these word probabilities (and our Naive Bayes assumptions) to assign probabilities to messages\"\n",
        "spam_probability(word_probs, message)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeiwyMMH_OC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}