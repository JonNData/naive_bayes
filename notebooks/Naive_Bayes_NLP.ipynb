{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive-Bayes-NLP.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNEftedRUJXe+5KPlGlF4jL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonNData/naive_bayes/blob/master/notebooks/Naive_Bayes_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xnU1sodYIu8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwG6BK2CokiI",
        "colab_type": "text"
      },
      "source": [
        "## Multinomial Naive Bayes\n",
        "Input X: array of messages  \n",
        "Input y: array of labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtocMzZxYTL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MNNaiveBayes:\n",
        "  def __init__(self, k=0.5):\n",
        "    self.k = k\n",
        "    self.cat0_count = 0\n",
        "    self.cat1_count = 0\n",
        "    self.total_count = self.cat0_count + self.cat1_count\n",
        "    self.cat_0_prior = 0\n",
        "    self.cat_1_prior = 0\n",
        "    self.cat_0_prior, self.cat_1_prior\n",
        "    self.word_probs = []\n",
        "    self.vocab = []\n",
        "\n",
        "  def tokenize(self, document):\n",
        "    \"\"\"\n",
        "    Take in a document and return a list of words\n",
        "    \"\"\"\n",
        "    doc = document.lower()\n",
        "    # remove non-alpha characters\n",
        "    stop_chars = '''0123456789!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "    \n",
        "    tokens = \"\"\n",
        "    # iterate through and make each token\n",
        "    for char in doc:\n",
        "      if char not in stop_chars:\n",
        "        tokens += char\n",
        "\n",
        "    return tokens.split() # now a list of tokens\n",
        "  \n",
        "  def count_words(self, X, y):\n",
        "    \"\"\"\n",
        "    X is an array of documents\n",
        "    y is an array of targets, 0 or 1\n",
        "    Output a dictionary of {word: (cat0_count, cat1_count)...}\n",
        "    \"\"\"\n",
        "    counts = {}\n",
        "    for document in X:\n",
        "      for category in y:\n",
        "        for token in self.tokenize(document):\n",
        "          # Initialize a dict entry with 0 counts\n",
        "          if token not in counts:\n",
        "            counts[token] = [0,0]\n",
        "          # Now that it exists, add to the category count for that word\n",
        "          counts[token][category] += 1\n",
        "    return counts\n",
        "\n",
        "  def prior_prob(self, counts):\n",
        "    \n",
        "    # Iterate through counts dict and add up each word count by category\n",
        "    cat0_word_count = cat1_word_count = 0\n",
        "    for word, (cat0_count, cat1_count) in counts.items():\n",
        "        cat0_word_count += cat0_count\n",
        "        cat1_word_count += cat1_count\n",
        "\n",
        "    # save attributes to the class\n",
        "    self.cat0_count = cat0_word_count\n",
        "    self.cat1_count = cat1_word_count\n",
        "    self.total_count = self.cat0_count + self.cat1_count\n",
        "\n",
        "    # Get the prior prob by dividing words in each cat by total words\n",
        "    cat_0_prior = cat0_word_count / self.total_count\n",
        "    cat_1_prior = cat1_word_count / self.total_count\n",
        "    return cat_0_prior, cat_1_prior\n",
        "\n",
        "  def word_probabilities(self, counts):\n",
        "    \"\"\"turn the word_counts into a list of triplets\n",
        "    word, p(w | cat0), and p(w | cat1)\"\"\"\n",
        "    # Here we apply the smoothing term, self.k, so that words that aren't in\n",
        "    # the category don't get calculated as 0\n",
        "    self.vocab = [word for word, (cat0, cat1) in counts.items()]\n",
        "    return [(word,\n",
        "    (cat0 + self.k) / (self.cat0_count + 2 * self.k),\n",
        "    (cat1 + self.k) / (self.cat1_count + 2 * self.k))\n",
        "    for word, (cat0, cat1) in counts.items()]\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    # Take all these functions and establish probabilities of input\n",
        "    counts = self.count_words(X, y)\n",
        "    self.cat_0_prior, self.cat_1_prior = self.prior_prob(counts)\n",
        "    self.word_probs = self.word_probabilities(counts)\n",
        "\n",
        "  def predict(self, test_corpus):\n",
        "    # Split the text into tokens,\n",
        "    # For each category: calculate the probability of each word in that cat\n",
        "    # find the product of all of them and the prior prob of that cat\n",
        "    y_pred = []\n",
        "    for document in test_corpus:\n",
        "      # Every document get their own prediction probability\n",
        "      log_prob_cat0 = log_prob_cat1 = 0.0\n",
        "      tokens = self.tokenize(document)\n",
        "        # Iterate through the training vocabulary and add any log probs that match\n",
        "        # if no match don't do anything. We just need a score for each category/doc\n",
        "      for word, prob_cat0, prob_cat1 in self.word_probs:\n",
        "        if word in tokens:\n",
        "          # Because of 'overflow' best to add the log probs together and exp\n",
        "          log_prob_cat0 += np.log(prob_cat0)\n",
        "          log_prob_cat1 += np.log(prob_cat1)\n",
        "        # get each of the category predictions including the prior\n",
        "      cat_0_pred = self.cat_0_prior * np.exp(log_prob_cat0)\n",
        "      cat_1_pred = self.cat_1_prior * np.exp(log_prob_cat1)\n",
        "      if cat_0_pred >= cat_1_pred:\n",
        "        y_pred.append(0)\n",
        "      else:\n",
        "        y_pred.append(1)\n",
        "    return y_pred\n",
        "      \n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqa0E78pK887",
        "colab_type": "text"
      },
      "source": [
        "## Let's test it. Later this will be a pytest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7Ofhq05jzSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data will be from reddit. \n",
        "# Train on 10 r/worldnews titles and 10 r/aww titles\n",
        "# test on 2 r/aww and 2 r/worldnews\n",
        "# category_0 = r/worldnews = 0 \n",
        "# category_1 = r/aww = 1\n",
        "worldnews = [\"Uighur group calls for China to lose 2022 Games over 'genocide'\", \n",
        "     \"Polish Towns That Declared Themselves ‘L.G.B.T. Free’ Are Denied E.U. Funds\",\n",
        "     \"Michelle Bolsonaro, Brazil's First Lady, Tests Positive For Coronavirus\",\n",
        "     \"Border officials crack down on Americans travelling through B.C. to Alaska\",\n",
        "     \"Hong Kong bans 11 pro-democracy figures from legislative election | Hong Kong Free Press HKFP\",\n",
        "     \"The 3 women who have brought COVID into Queensland have been charged with falsifying documents and fraud\",\n",
        "     \"UK KFC admits a third of its chickens suffer painful inflammation - Fast food giant KFC has laid bare the realities of chicken production after admitting to poor welfare conditions among its suppliers.\",\n",
        "     \"Chile picks Japan's trans-Pacific cable route in snub to China\",\n",
        "     \"Hackers post fake stories on real news sites 'to discredit Nato'\",\n",
        "     \"Prostate cancer can be detected by a new blood test which also reveals the severity of the disease with 99 per cent accuracy\"\n",
        "    ]\n",
        "aww = [\n",
        "       \"This little cutie climbed up on me while I applied to adopt her\",\n",
        "       \"Here is a happy duckling to make your day better!\",\n",
        "       \"Adorable cutie\",\n",
        "       \"12 years ago she came running up to me on a dirt road and sat on my foot clinging to my ankle crying. Today I present to you my kitty Izzy.\",\n",
        "       \"Very talented Otter\",\n",
        "       \"A dog at the shelter I work at is teaching me how to smile.\",\n",
        "       \"The best seat in the house\",\n",
        "       \"A Stork couple celebrating their first egg \",\n",
        "       \"She turned 6 last week. Everyone still thinks she's a kitten.\",\n",
        "       \"My gf and I rescued this little guy today.... meet max everyone\"\n",
        "]\n",
        "X = worldnews + aww\n",
        "y = [0]*10 + [1]*10\n",
        "\n",
        "X_test = [\n",
        "          \"Toronto emerging as tech superpower as immigrants choose Canada over US\",\n",
        "          \"\"\"Egypt imprisons female TikTok influencers: A court in Cairo has sentenced six young female bloggers to prison for up to two years — not for political offenses, but for violating \"public morals.\" Activists have called the ruling an \"outrageous attack on civil liberties.\"\"\",\n",
        "          \"The mixed kitten seeds grew well this year.\",\n",
        "          \"My wife just sent me this photo of our cat at the vet. Safe to say she’s a little scared.\"\n",
        "]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LyA7Y4bNh88",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "731c2fc3-bcea-46a7-bf62-5133b390fac2"
      },
      "source": [
        "mnnb = MNNaiveBayes()\n",
        "mnnb.fit(X,y)\n",
        "mnnb.predict([\"cat\", \"cute\", \"dog\"])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    }
  ]
}